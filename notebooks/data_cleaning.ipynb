{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_language_detection import LanguageDetector\n",
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "    return lines\n",
    "\n",
    "def save_file(file, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        for line in file:\n",
    "            f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = read_file(\"data/raw/train.de\")\n",
    "# en = read_file(\"data/raw/train.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_entities = {\n",
    "    '&quot;': '',\n",
    "    '&apos;': \"'\",\n",
    "    '&amp;': 'und',\n",
    "    '&lt;': '',\n",
    "    '&gt;': '',\n",
    "    '&#124;': '',\n",
    "    '&#93;': ')',\n",
    "    '&#91;': '(',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quotes(string):\n",
    "    # Replace „“” with \"\n",
    "    string = string.replace('„', '\"').replace('“', '\"').replace('”', '\"').replace('’', '\"').replace('‘', '\"')\n",
    "    # Remove \" if not closed, not ideal way but it should be enough\n",
    "    if '\"' in string and string.count('\"') % 2 != 0:\n",
    "        string = string.replace('\"', '')\n",
    "    return string\n",
    "\n",
    "\n",
    "def clean_de_strings(strings):\n",
    "    transformed_strings = []\n",
    "    \n",
    "    for string in tqdm(strings, desc=\"Cleaning strings\", total=len(strings), ncols=100):\n",
    "\n",
    "        # Replace amp_entities\n",
    "        for entity, replacement in amp_entities.items():\n",
    "            string = string.replace(entity, replacement)\n",
    "        \n",
    "        # Replace {} and [] with ()\n",
    "        string = string.replace('{', '(').replace('}', ')')\n",
    "        string = string.replace('[', '(').replace(']', ')')\n",
    "\n",
    "        # Replace weird symbols\n",
    "        string = string.replace('Гј', 'ü')\n",
    "        string = string.replace('Г ¶ ', 'ö')\n",
    "        string = string.replace('Г ¤ ', 'ä')\n",
    "        string = string.replace('Гџ', 'ß')\n",
    "        string = string.replace('–', '-')\n",
    "        string = string.replace('� ber', 'über')\n",
    "\n",
    "        # Delete weird symbols\n",
    "        string = re.sub(r'##UNDERSCORE##', '', string)\n",
    "        string = re.sub(r'##AT##-##AT##', '', string)\n",
    "        string = re.sub(r'##AT##', '', string)\n",
    "        string = re.sub(r'##STAR##', '', string)\n",
    "        string = re.sub(r'\\(\\s*\\)', '', string)\n",
    "        string = re.sub(r'\\( . \\)', '', string)\n",
    "        string = re.sub(r'[-]+', '', string)\n",
    "        string = re.sub(r'/\\s*/', '', string)\n",
    "        string = re.sub(r'\\\\', '', string)\n",
    "        string = re.sub(r'[<>®™©°«»…†„“”Σ‡‰‹•¦+=±¿]', '', string)\n",
    "        string = re.sub(r'\\( \\(', '', string)\n",
    "        string = re.sub(r'\\) \\)', '', string)\n",
    "\n",
    "        # Replace excessive characters\n",
    "        string = re.sub(r'\\.(\\s*\\.)+', '.', string)\n",
    "        string = re.sub(r',(\\s*,)+', ',', string)\n",
    "        string = re.sub(r'\\!(\\s*\\!)+', '!', string)\n",
    "        string = re.sub(r'\\?(\\s*\\?)+', '?', string)\n",
    "        string = re.sub(r':(\\s*:)+', ':', string)\n",
    "        string = re.sub(r';(\\s*;)+', ';', string)\n",
    "\n",
    "        # Remove quotes\n",
    "        string = remove_quotes(string)\n",
    "\n",
    "        # # Remove excessive punctuation\n",
    "        string = re.sub(r'([,:\\.;]\\s){2,}', r'', string)\n",
    "        string = re.sub(r',\\s*\\.$', '.', string)\n",
    "        string = re.sub(r', \\. ([A-Z])', '\\. \\1', string)\n",
    "        string = re.sub(r', \\. ([a-z])', ', \\1', string)\n",
    "        \n",
    "        # Remove excessive spaces\n",
    "        string = \" \".join(string.split())\n",
    "\n",
    "        # Lowercase string\n",
    "        string = string.lower()\n",
    "\n",
    "        # Add cleaned string to list\n",
    "        transformed_strings.append(string)\n",
    "    return transformed_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning strings: 100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 5576.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ax : 41 ( 91 ) 910 57 77 ) checkin : 14 : 00 ; checkout',\n",
       " 'als übereinander der benq bordeaux , trocken rot und quot gereicht .',\n",
       " 'ist grösser jahres möglich . ausschließlich kanälen der ukraine theaterfestival рѓв сњс сљс € с die arche .',\n",
       " 'wendn . u . (hello) . keine seiten / mit schlusselwortern oder unterkategorien entdeckst , die sich auf die texte in deiner homepage beziehen , kannst du deine eigenen seiten mit schlusselwortern oder unterkategorien vorschlagen und schaffen , / i verbunden mit . satellite . und du kannst deine kontextuellen listings dort unentgeltlich und in realer zeit hinzufugen .',\n",
       " 'diese funktion ist ein alias für : imap listscan .',\n",
       " 'diese ! funktion ist ein ! alias für ! : oci collection free .',\n",
       " 'diese funktion ist ? ein alias ? für : imap listscan .',\n",
       " 'ferienwohnungen | hotels | pensionen | campings | unterhaltung | last minute angebote !',\n",
       " 'was heißt hier eigentlich auf eigene gefahr ?',\n",
       " 'es ist nicht so gravierend wie das , worüber sie hier diskutieren , aber in allen mitgliedstaaten gibt es gelegentlich naturkatastrophen und ich denke dabei auch an die countys , die ich vertrete offaly , http : en.wikipedia.org / wiki / county laois \" o \" county laois und louth wo es außerhalb der üblichen saison äußerst ungewöhnliche überschwemmungen gab .',\n",
       " '( beispiel eris ) ( ds9 der plan des dominion ) der glaube der']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_de_strings([\"ax : 41 ( 91 ) 910 57 77 ) , . checkin : 14 : 00 ; checkout \", \"als � bereinander , . Der BenQ ( . ) ( 3 ) , . , ; Bordeaux , trocken rot + • = und quot gereicht , .\", \"ist grГ ¶ sser Jahres mГ ¶ glich . ausschlieГџlich KanГ ¤ len der Ukraine  Theaterfestival РЃв – СЊС ‘ СЉС € С ‰ die Arche .\", 'Wendn„“” ##AT##-##AT##... /  / u . {hello} .. ( ) keine Seiten / mit Schlusselwortern oder Unterkategorien entdeckst , die sich auf die Texte in deiner Homepage beziehen , kannst du deine eigenen Seiten mit Schlusselwortern oder Unterkategorien vorschlagen und schaffen , / i > verbunden mit … \" . satellite .  und du kannst deine kontextuellen Listings dort unentgeltlich und in realer Zeit hinzufugen .', \"Diese ( ) Funktion ()ist ein  Alias für : imap ##UNDERSCORE## listscan ( ) .\", \"Diese ! Funktion ist ein ! ! ! Alias für ! !! : OCI  --Collection--- > free .\", \"Diese Funktion ist ? ? ? ein Alias ?? für : imap ##UNDERSCORE## listscan ( ) .\", \"Ferienwohnungen | Hotels | Pensionen | Campings | Unterhaltung | Last Minute Angebote ! !\", 'Was heißt hier eigentlich \" auf eigene Gefahr  ?', 'Es ist nicht so gravierend wie das , worüber Sie hier diskutieren , aber in allen Mitgliedstaaten gibt es gelegentlich Naturkatastrophen und ich denke dabei auch an die Countys , die ich vertrete - Offaly , http : / / {} en.wikipedia.org / wiki / County ##UNDERSCORE## Laois \" \\ o \" County Laois  und Louth - wo es außerhalb der üblichen Saison äußerst ungewöhnliche Überschwemmungen gab .', \"( Beispiel ( ( Eris ) ) ) ( ( ( DS9 Der Plan des Dominion ) ) ) Der ( ( Glaube ) ) der\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning strings: 100%|████████████████████████████████| 4468840/4468840 [02:35<00:00, 28794.71it/s]\n"
     ]
    }
   ],
   "source": [
    "de_clean = clean_de_strings(de)\n",
    "save_file(de_clean, \"data/clean/clean.de\")\n",
    "de_clean = read_file(\"data/clean/clean.de\")\n",
    "save_file(de_clean, \"data/clean/clean.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_clean = read_file(\"data/clean/clean.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting words: 100%|████████████████████████████████| 4468840/4468840 [01:15<00:00, 59444.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7027"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_words_with_separator(strings, separator=\"�\"):\n",
    "    pattern = r'[a-zA-Z]+\\s+' + re.escape(separator) + r'\\s+[a-zA-Z]+'\n",
    "    extracted_words = []\n",
    "\n",
    "    for string in tqdm(strings, desc=\"Extracting words\", total=len(strings), ncols=100):\n",
    "        matches = re.findall(pattern, string)\n",
    "        for match in matches:\n",
    "            match = match.replace(\" \", \"\").replace(separator, \"_\").lower()\n",
    "            extracted_words.append(match)\n",
    "\n",
    "    return set(extracted_words)\n",
    "\n",
    "words = extract_words_with_separator(de_clean)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_language_detection.spacy_language_detector.LanguageDetector at 0x274cfaed450>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector(seed=42)\n",
    "\n",
    "nlp_model = spacy.load(\"de_core_news_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp_model.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_unk_words(words, nlp_model):\n",
    "    special_characters = list(\"äöü\")\n",
    "    resolved_words = []\n",
    "    unresolved_words = []\n",
    "    for word in tqdm(words, desc=\"Resolving words\", total=len(words), ncols=100):\n",
    "        ok = False\n",
    "        for character in special_characters:\n",
    "            option = word.replace(\"_\", character)\n",
    "            doc = nlp_model(option)\n",
    "            language = doc._.language\n",
    "            if language[\"language\"] == \"de\" and language[\"score\"] > 0.9:\n",
    "                resolved_words.append(option)\n",
    "                ok = True\n",
    "                break\n",
    "        if not ok:\n",
    "            unresolved_words.append(word)\n",
    "    return resolved_words, unresolved_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving words: 100%|██████████████████████████████████████████| 7027/7027 [02:39<00:00, 44.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4308, 2719)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolved, unresolved = resolve_unk_words(words, nlp_model)\n",
    "len(resolved), len(unresolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_words = [\n",
    "    \"können\", \n",
    "    \"gebühren\",\n",
    "    \"gebühr\",\n",
    "    \"schüler\", \n",
    "    \"universitäten\", \n",
    "    \"müssen\", \n",
    "    \"grundsätzlich\", \n",
    "    \"fächern\", \n",
    "    \"maßnahmen\", \n",
    "    \"möglichkeit\",\n",
    "    \"studiengänge\",\n",
    "    \"qualität\",\n",
    "    \"produktivität\",\n",
    "    \"prüfungen\",\n",
    "    \"bedürfnissen\",\n",
    "    \"bedürfen\",\n",
    "    \"trägt\",\n",
    "    \"förderunterricht\",\n",
    "    \"verlängerung\",\n",
    "    \"unterstützungsangebot\",\n",
    "    \"studienplätze\",\n",
    "    \"förderbedarf\",\n",
    "    \"zuschüsse\",\n",
    "    \"kommunalbehörden\",\n",
    "    \"behörden\",\n",
    "    \"ausbildungsmaßnahmen\",\n",
    "    \"rehabilitationsmaßnahmen\",\n",
    "    \"regulären\",\n",
    "    \"arbeitsmarktbehörden\",\n",
    "    \"behindertenwerkstätten\",\n",
    "    \"tätigkeit\",\n",
    "    \"während\",\n",
    "    \"schulungübernimmt\",\n",
    "    \"beschäftigung\",\n",
    "    \"höhe\",\n",
    "    \"völlig\",\n",
    "    \"seriös\",\n",
    "    \"vergnügen\",\n",
    "    \"millionäre\",\n",
    "    \"grosszügigen\",\n",
    "    \"benötigt\",\n",
    "    \"verfügbar\",\n",
    "    \"tätige\",\n",
    "    \"dürfen\",\n",
    "    \"gängigen\",\n",
    "    \"hören\",\n",
    "    \"großartige\",\n",
    "    \"SpaßMobiles\",\n",
    "    \"reguläre\",\n",
    "    \"gültig\",\n",
    "    \"beträgt\",\n",
    "    \"füllen\",\n",
    "    \"fülle\",\n",
    "    \"großbritannien\",\n",
    "    \"kämpfen\",\n",
    "    \"nervös\",\n",
    "    \"nähe\",\n",
    "    \"silberküste\",\n",
    "    \"erklären\",\n",
    "    \"debütalbum\",\n",
    "    \"Livequalitäten\",\n",
    "    \"trüffel\",\n",
    "    \"weiß\",\n",
    "    \"südostküste\",\n",
    "    \"günstigen\",\n",
    "    \"motorräder\",\n",
    "    \"künftig\",\n",
    "    \"hosenbügler\",\n",
    "    \"frühstücksbuffet\",\n",
    "    \"große\",\n",
    "    \"großes\",\n",
    "    \"erklärt\",\n",
    "    \"geäußerten\",\n",
    "    \"undäberprüfung\",\n",
    "    \"präzisionsprodukte\",\n",
    "    \"gießvorgang\",\n",
    "    \"gleichmäßige\",\n",
    "    \"gießform\",\n",
    "    \"präzise\",\n",
    "    \"kürzeste\",\n",
    "    \"mängel\",\n",
    "    \"zumäbermäßigen\",\n",
    "    \"statusgemäße\",\n",
    "    \"prüfer\",\n",
    "    \"patentansprüche\",\n",
    "    \"fällt\",\n",
    "    \"unstatutengemäße\",\n",
    "    \"neuerlicheäberprüfung\",\n",
    "    \"könne\",\n",
    "    \"lösung\",\n",
    "    \"unabhängig\",\n",
    "    \"mögen\",\n",
    "    \"sekundärer\",\n",
    "    \"abschlieäenderöffnung\",\n",
    "    \"phänomene\",\n",
    "    \"hütte\",\n",
    "    \"binär\",\n",
    "    \"binäre\",\n",
    "    \"heißt\",\n",
    "    \"vollständig\",\n",
    "    \"enthält\",\n",
    "    \"verständnis\",\n",
    "    \"jüngeren\",\n",
    "    \"verkantete\",\n",
    "    \"gültigen\",\n",
    "    \"könnte\",\n",
    "    \"lagen\",\n",
    "    \"präzedenzfälle\",\n",
    "    \"bekräftigte\",\n",
    "    \"lösende\",\n",
    "    \"lösenden\",\n",
    "    \"nehmenäwurden\",\n",
    "    \"nehmenäwurde\",\n",
    "    \"lektüre\",\n",
    "    \"autoritäts\",\n",
    "    \"dafür\",\n",
    "    \"auslösen\",\n",
    "    \"lösen\",\n",
    "    \"gummisöffnen\",\n",
    "    \"räumt\",\n",
    "    \"räumte\",\n",
    "    \"enthält\",\n",
    "    \"nötigen\",\n",
    "    'nötige',\n",
    "    \"gelöst\",\n",
    "    \"gelöste\",\n",
    "    \"müsste\",\n",
    "    \"müssten\",\n",
    "    \"erklärte\",\n",
    "    \"erklärten\",\n",
    "    \"naturphänomen\",\n",
    "    \"aktivität\",\n",
    "    \"endgültigen\",\n",
    "    \"trophäe\",\n",
    "    \"popularität\",\n",
    "    \"regelmässig\",\n",
    "    \"märz\",\n",
    "    \"seriöse\",\n",
    "    \"mittelständler\",\n",
    "    \"kostengünstig\",\n",
    "    \"kostengünstige\",\n",
    "    \"spüren\",\n",
    "    \"luxuriöses\",\n",
    "    \"verstoßen\",\n",
    "    \"könnens\",\n",
    "    \"männer\",\n",
    "    \"glücksmail\",\n",
    "    \"brüllt\",\n",
    "    \"stürmt\",\n",
    "    \"prüfen\",\n",
    "    \"regelmässig\",\n",
    "    \"getätigt\",\n",
    "    \"Vergnügungslokalen\",\n",
    "    \"rätsel\",\n",
    "    \"einemäusserst\",\n",
    "    \"stärken\",\n",
    "    \"stärke\",\n",
    "    \"glastüren\",\n",
    "    \"gäste\",\n",
    "    \"atmosphäre\",\n",
    "    \"gläser\",\n",
    "    \"geprüft\",\n",
    "    \"münzen\",\n",
    "    \"münze\",\n",
    "    \"privatsphäre\",\n",
    "    \"tür\",\n",
    "    \"luxuriöses\",\n",
    "    \"luxuriöseste\",\n",
    "    \"luxuriösesten\",\n",
    "    \"geschäftsmännern\",\n",
    "    \"garten\",\n",
    "    \"jörg\",\n",
    "    \"Vogel\",\n",
    "    \"königspalast\",\n",
    "    'gemälden',\n",
    "    \"antiquitäten\",\n",
    "    \"gebäuden\",\n",
    "    \"könnten\",\n",
    "    \"frühstück\",\n",
    "    \"Inquisicion\",\n",
    "    \"verknüpft\",\n",
    "    \"türkisch\"\n",
    "]\n",
    "resolved.extend(additional_words)\n",
    "resolved = list(set(resolved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unk_words(strings, resolved, separator=\"�\"):\n",
    "    replaced = []\n",
    "    pattern = r'[a-zA-Z]+\\s+' + re.escape(separator) + r'\\s+[a-zA-Z]+'\n",
    "    for string in tqdm(strings, desc=\"Extracting words\", total=len(strings), ncols=100):\n",
    "        matches = re.findall(pattern, string)\n",
    "        for match in matches:\n",
    "            for resolved_word in resolved:\n",
    "                if distance(match.replace(\" \", \"\").lower(), resolved_word) == 1:\n",
    "                    string = string.replace(match, resolved_word)\n",
    "        replaced.append(string)\n",
    "    return replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting words: 100%|████████████████████████████████| 4468840/4468840 [03:01<00:00, 24603.64it/s]\n"
     ]
    }
   ],
   "source": [
    "de_replaced = replace_unk_words(de_clean, resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(de_replaced, \"data/clean/clean.de\") # 9600 -> 8900 -> 8100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_clean = read_file(\"data/clean/clean_v1.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some non German sentences in .de file\n",
    "# 0 -> 50\n",
    "# 1345 -> 1360\n",
    "# 3610 -> 3625\n",
    "\n",
    "# 308488 -> 308700\n",
    "# 312085 -> 312180\n",
    "# 1557748 -> 1557880\n",
    "\n",
    "def final_clean(strings):\n",
    "    transformed_strings = []\n",
    "    for string in tqdm(strings, desc=\"Cleaning strings\", total=len(strings), ncols=100):\n",
    "        string = re.sub(r', . ', '', string)\n",
    "        string = re.sub(r'. , ', '', string)\n",
    "        string = re.sub(r'�', '', string)\n",
    "        string = re.sub(r'ã ¼ ', 'ü', string)\n",
    "        string = re.sub(r'ã  ', 'ß', string)\n",
    "        string = re.sub(r'ã ¶ ', 'ö', string)\n",
    "        string = re.sub(r'ã ¤ ', 'ä', string)\n",
    "        string = re.sub(r'ă ¤ ', 'ä', string)\n",
    "        string = re.sub(r'', '', string)\n",
    "        transformed_strings.append(string)\n",
    "    return transformed_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning strings: 100%|███████████████████████████████| 4468840/4468840 [00:40<00:00, 110731.13it/s]\n"
     ]
    }
   ],
   "source": [
    "de_clean = final_clean(de_clean)\n",
    "save_file(de_clean, \"data/clean/clean_v1.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_apostrophe_en(strings):\n",
    "    transformed_strings = []\n",
    "    pattern = r\"\\b(wasn � t|musn � t|isn � t|can � t|don � t|didn � t|won � t|haven � t|that � s|it � s)\\b\"\n",
    "    for string in tqdm(strings, desc=\"Cleaning strings\", total=len(strings), ncols=100):\n",
    "        string = string.lower()\n",
    "        string = re.sub(pattern, lambda match: match.group().replace('�', \"'\"), string)\n",
    "        transformed_strings.append(string)\n",
    "    return transformed_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning strings: 100%|███████████████████████████████| 4468840/4468840 [00:28<00:00, 158735.84it/s]\n"
     ]
    }
   ],
   "source": [
    "de_clean = fix_apostrophe_en(de_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(de_clean, \"data/clean/clean.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'cs', 'score': 0.857137658806668}\n"
     ]
    }
   ],
   "source": [
    "txt = \"ďîääĺđćęŕ číäčâčäóŕëüíűő řŕáëîíîîňâĺ ÷ ŕţůčő çŕ âíĺříčé âčä ńŕéňŕ .\"\n",
    "doc = nlp_model(txt)\n",
    "language = doc._.language\n",
    "print(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_clean = read_file(\"data/clean/clean.en\")\n",
    "save_file(de_clean, \"data/clean/clean.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
